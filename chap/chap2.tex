% vim:ts=4:sw=4
% Copyright (c) 2014 Casper Ti. Vector
% Public domain.
\chapter{复杂姿态人脸检测}
人类的思维活动是以对客观世界的认识为基础的，感觉是人类的大脑与周围世界发生联系的窗口。人脑在每天的感知活动中要从3万个听觉神经和1万个视觉神经的输入中抽取出有意义的信息，其中，约有80\%的信息来自视觉。人脸检测(Face Detection)的目的是为了确定图像中人脸的位置、大小和数量，它是模式识别和计算机视觉领域中的重要研究方向。人脸检测最初被作为自动人脸识别系统的定位环节被提出，并因其重要性在 20 世纪 90 年代以后作为一个独立的课题而备受研究者们的关注，并提出大量的人脸检测算法。

\section{人脸检测研究概述}
人脸检测就是判断图片中是否有人脸存在，如果存在,则输出各个人脸的位置和大小。人脸检测是人脸识别的基础，如果人脸检测出现错误的话，后续的人脸识别基本无法进行。衡量人脸检测算法的好坏主要有以下三个指标:（1）召回率，即正确检测到的脸的数量与数据库中总的脸的数量之比。这个指标反映了检测器可以正确找到多少人脸。（2）精确度，即在所有输出的人脸中，正确的人脸所占的比例。这个指标反映了检测器检出结果的可靠程度。（3）稳定度，即当人脸在图片中的位置和大小发生变化时，输出的人脸位置和大小也需要相对于真实人脸保持不变，一般用标注的位置和检测到的位置的重合度来衡量。越稳定的人脸检测结果对于后序的人脸校准操作越有利。这三个指标越高，人脸检测算法越好。到目前为止，最具有里程碑意义的人脸检测算法是文献\parencite{viola2001rapid}，它奠定了现代人脸检测算法的基础。为了解决文献\parencite{viola2001rapid}不能很好的处理多角度的问题，随后也出现了许多针对多角度人脸检测的经典算法
\supercite{Li2002Statistical,Wu2004Fast,Huang2007High,Li2011Face,Li2014Efficient}。有关人脸检测技术的发展，读者可以参考综述文献\parencite{surveyface}。

早期的人脸检测和识别技术研究主要针对正面、简单背景下的人脸图像。然而，人脸图像易受如下自身的可变因素和外界条件的影响：(1) 外貌、表情、肤色等的不同，使人脸具有模式可变性；(2) 光照的影响，曝光及外在光源等引起的图像中亮度、对比度的不同；(3) 眼镜、头发和饰物以及其它外部物体等引起面部图像的部分遮挡；(4) 人脸与摄像头之间的相对运动引起人脸姿态的多样性，如平面内旋转、平面外偏转及俯仰等变化。不同姿态下的二维图像投影引起的三维脸部不同部位的拉伸、压缩及遮挡，这样即使是同一个人在不同姿态下的二维人脸图像也存在较大差异；(5) 摄像设备性能的不同、相机焦距、噪声等引起的成像条件差异；(6) 复杂背景对人脸目标的干扰。受这些因素的影响，图像中人脸的模式存在很强的多样性，这使得复杂环境下的人脸检测和识别是一个极富挑战性的研究课题。随着机器学习等人工智能方法的引入，人脸的检测和识别算法可以通过自适应的学习训练数据中的知识，逐步提高解决复杂背景下的人脸检测和识别的能力。因而，本文致力于采用机器学习的方法解决复杂背景下的多姿态人脸检测与识别问题。由于人脸的姿态变化和观察视角的不同是相对的，所以在本文中姿态和视角是相互通用的。

统计表明75\%的家庭照片中的人脸并非正面人脸，并且在实际应用中由于人体的运动或摄像设备的移动，使得正面人脸图像的获取比较困难。另外在智能监控视频当中，由于摄像头位置和角度问题，检测的人脸大多为非正面。为此多姿态人脸检测算法受到越来越多的关注。Rowley将Viola的方法推广到多视角人脸检测，针对不同角度训练多个网络，并采用姿态预估计加快检测速度；Schneiderman等
\supercite{schneiderman2004object}将人脸划分为左侧面、正面和右侧面，分别训练了三个不同视图的检测器来分别处理这三种情况；Li等\supercite{Li2004Support}则用SVM进行多姿态人脸的检测和识别；Feraud等
\supercite{Rapha1997A}采用Constrained Generative Model构造了四个人脸检测器分别针对左右偏转$[0^\circ,20^\circ]$和$[20^\circ,40^\circ]$的人脸进行检测。Li等
\supercite{Zhang2002Multi}手动的将人脸训练样本分成几个较均匀的子视角类，提出了Floatboost学习方法，训练得到“由粗到细”的金字塔型结构人脸检测器，用于近乎实时的多视角人脸检测。

人脸特征表示的好坏,直接关系到了人脸检测与识别的精度的高低。因此，如何得到具有表达力的人脸特征,就是人脸检测与识别的最关键的问题。纵观30多年的人脸识别的研究历史，我们发现人脸识别技术的发展本质上也就是人脸特征的发展。特征提取的作用就是根据已知的人脸的位置信息，提取出对于人脸识别有利的信息,如面部区域、纹理结构等，而去掉和人脸识别无关的，如背景、噪声等信息。一个优秀的人脸特征需要满足以下两个要求：（1）该特征需要对不同人之间的细微区别十分敏感。（2）同时，该特征需要对人脸角度、光照、表情等变化具有一定的不变性。目前人脸识别技术中,运用的最多的特征有以下几种LBP\supercite{Ojala2002Gray}，SIFT\supercite{Lowe2004Distinctive}，HOG\supercite{Dalal2005Histograms}，Gabor\supercite{Liu2002Gabor}，LE\supercite{LE}等。这些特征在广泛的应用中均取得了不错的识别精度。目前，由于深度学习（deep learning）的发展,也有许多基于深度学习的算法将特征提取和特征学习融合到同一个框架中，其中包括:DeepFace\supercite{Taigman2014DeepFace}、DeepID\supercite{Sun2014Deep}、FaceNet\supercite{Schroff2015FaceNet}等。由于深度神经网络强大的拟合能力，这类方法在各种人脸识别问题中均取得了十分优秀的结果。但是由于这类方法网络结构复杂，模型参数一般都在百万量级。模型大小一般为几百兆,在实际使用中不太方便。另外，这类方法需要硬件支持并行计算，不适合手机或嵌入式系统上的人脸识别。因此，深度学习算法一般运用在云计算中。目前有许多公司提供基于深度学习的人脸云计算服务，例如:Face++、Microsoft、SenseTime、Tencent等。

\section{人脸检测和识别中的特征}
\subsection{Haar-Like特征}
（1）Haar-Like特征简介。

Haar-like特征最早是由Papageorgiou等人提出并应用于人脸表示，Viola和Jones在此基础上，使用3种类型4种形式的特征。在人脸检测的过程中，需要AdaBoost级联分类器，分类器的训练则要在图像中选取一些简单特征，这些抽取的特征由各个矩形特征组成，称为Haar特征。Haar特征是计算机视觉领域一种常用的特征描述算子，基本Haar特征原型只有四种，而扩展的类Haar特征分为三类：边缘特征、线性特征和中心特征，它们组合成为特征模板。如图\ref{fig_haar}所示\supercite{ExtendHaar}。
\begin{figure}[!h] \centering
  \includegraphics[width=.6\textwidth]{figure/fig_haar.eps}
  \bicaption[类Haar特征]{类Haar特征~\label{fig_haar}}{Haar-like features}
\end{figure}
图中特征模板内有白色和黑色区域，分别对应于正权值和负权值，即特征值为白色矩形像素灰度值的和减去黑色矩形像素灰度值的和。Haar特征值反映了图像的灰度变化情况。例如：脸部的一些特征能由矩形特征简单的描述，如：眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。但矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向（水平、垂直、对角）的结构。通过改变特征模板的大小和位置，可在图像子窗口中穷举出大量的特征。上图的特征模板称为“特征原型”，特征原型在图像子窗口中扩展（平移伸缩）得到的特征称为“矩形特征”，矩形特征的值称为“特征值”。矩形特征可位于图像任意位置，大小也可以任意改变，所以矩形特征值是矩形模版类别、矩形位置和矩形大小这三个因素的函数。故类别、大小和位置的变化使得很小的检测窗口含有非常多的矩形特征，如：在$24\times24$像素大小的检测窗口内矩形特征数量可以达到16万个，这样就有两个问题需要解决：（1）如何快速计算那么多的特征？（2）哪些矩形特征才是对分类器分类最有效的？Viola和Jones在人脸检测当中提出了通过积分图快速计算haar-like特征，通过Adaboost进行特征选择。

（2）积分图的快速计算。

积分图的概念最早是由Paul Viola等人提出的，并被应用到实时的对象检测框架中。对于一个灰度图像而言，其积分图也是一张图，只不过这个图跟普通的灰度图，彩色图稍有不同。这是因为，一般我们说的灰度图、彩色图都是相机拍摄到的真实物体在某个时刻的真实画面。而积分图虽然也可以理解为一张图，但该图上任意一点(x,y)的值是指从灰度图像的左上角与当前点所围成的矩形区域内所有像素点灰度值之和。积分图的表示方法对Haar特征的快速计算有重要意义。积分图表示方法如图\ref{fig_itegral}所示。
\begin{figure}[!h] \centering
  \includegraphics[width=.6\textwidth]{figure/fig_itegral.eps}
  \bicaption[积分图]{积分图~\label{fig_itegral}}{Integral image}
\end{figure}

在这个积分图像中，每一点的值表示图像中该点位置左上部分区域内的所有像素的灰度值积分。如公式\ref{equ_integral}所示。
\begin{equation}
ii(x,y) = \sum_{x'\leq x,y'\leq y}i(x',y')
\label{equ_integral}
\end{equation}
其中$ii(x,y)$是图像中$(x,y)$点的像素灰度值积分，$i(x',y')$是图像中$(x',y')$点的像素灰度值。如果计算积分图像中某一区域的像素灰度值积分，则由该区域四个顶点对应的积分值作相应的加减运算得到。例如，区域D的积分$S_{D}$可由图像中1，2，3，4点的积分值$S_{1}$，$S_{2}$，$S_{3}$，$S_{4}$计算得到，即:
\begin{equation}
S_{D} = S_{4} + S_{1} - S_{2} -S_{3}
\end{equation}

图像中每点的积分值保存在内存中，计算某区域积分值变成了简单的加减运算，不必重新计算该区域像素和，计算消耗的时间是常量，所以不管图像尺寸如何，积分图表示方法可以降低特征值的计算复杂度。

\subsection{LBP特征}
（1）基本LBP

LBP（Local Binary Pattern）是一种用来描述图像局部纹理特征的算子。原始LBP算子是由Ojala\supercite{Ojala2002Gray}等人于1996年提出，用来提取纹理图像的特征，并且验证了它在纹理分类中的强大能力。由于其在纹理分类中优良的有效性及其计算简单，且对单调的灰度变化具有不变性等特点，它也被普遍应用于人脸检测、人脸识别以及表情分析和背景建模等领域。基本的LBP算子定义为在$3\times3$的窗口内，以窗口中心像素为阈值，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，$3\times3$领域内的8个点可产生8比特（bit）的无符号数，即得到该窗口的LBP值，并用这个值来反映该区域的纹理信息. 如图\ref{fig_lbp_1}所示。
\begin{figure}[!h] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_lbp_1.eps}
  \bicaption[基本LBP算子示意图]{基本LBP算子示意图~\label{fig_lbp_1}}{Illustration of basic LBP}
\end{figure}

上述十进制的形式可以用一个8比特的一个字节来表示，其表达式为：
\begin{equation}
LBP(x_c,y_c)=\sum_{n=0}^{7}s(i_n-i_c)2^n
\label{equ_lbp}
\end{equation}
其中，对于像素点位置$(x_c,y_c)$，其对应的像素的值为$i_c$，并作为中心点位置，将有8个像素点$i_n(n=0，1,2...7)$对其依次环绕，左上角为第一个像素点。二值化处理函数定义为：
\begin{equation}
s(x)=\left\{\begin{matrix}
1 &  if &  x\geq 0\\
0 &  if &  x < 0
\end{matrix}\right.
\label{equ_lbp2}
\end{equation}
下图\ref{fig_lbp_img}展示了一副人脸图片经过LBP算子运算之后得到的图像。
\begin{figure}[h] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_lbp_img.eps}
  \bicaption{原始图像（左）经LBP算子处理后的图像（右）~\label{fig_lbp_img}}{Original image (left) processed by the LBP operator (right).}
\end{figure}

（2）多尺度LBP

Ojala等人在后续工作中又对基本的LBP算子进行了拓展，使得邻域的范围不单局限在$3\times3$ 的邻域。如图\ref{fig_lbp_2}所示. 为了避免图像旋转中LBP值变化的缺陷，提出了旋转不变模式的LBP，更进一步得到了等价模式的LBP。使用圆形邻域以及双线性差值的方法就可以将LBP算子扩展到任意圆半径和任意邻域像素数目，使用表示$LBP_{P,R}$方法来表示领域参数，$P$ 表示邻域像素个数，$R$表示领域的圆周半径，图\ref{fig_lbp_2}分别依次给出了$LBP_{8,1}$、$LBP_{8,2}$和$LBP_{8,2.5}$三种模式。
\begin{figure}[!ht] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_lbp_2.eps}
  \bicaption{三种多尺度LBP~\label{fig_lbp_2}}{Three type of multi-scale LBP}
\end{figure}

（3）旋转不变LBP

邻域有$P$个点的$LBP$算子可以产生$2^P$种不同的模式，每个模式对应着$P$个相邻像素所组成的$2^P$个不同的二进制值。当图像发生旋转时，$P$个相邻像素也将绕着中心点沿圆形邻域的圆周旋转一定的角度，因此会使得$LBP_{P,R}$值发生改变。为了避免这个缺陷，Ojala又对$LBP_{P,R}$值进行重新定义，提出了具有旋转不变性的局部二值模式为：
\begin{equation}
LBP^{ri}_{P,R}=min\left \{ ROR(LBP_{P,R},i)|i=0,1,\cdots ,p-1 \right \}
\label{equ_lbp3}
\end{equation}
上式中，$LBP^{ri}_{P,R}$代表旋转不变 LBP 算子，$ROR(x,i)$为定义在$P$位数值$x$上的$i$位循环右移。如果对应图像采样的像素点来说，也就是对这$P$个像素点按照顺时针方向转动$i$次。由公式看出，对于那些不断旋转得到的$LBP$模式取其最小值就是$LBP$的旋转不变模式。引入旋转不变模式定义后，使得LBP纹理特征对于图像旋转表现得更加鲁棒并且也减少了LBP模式的种类。

（4）LBP等价模式
尽管$LBP^{ri}_{P,R}$在理论上旋转不变性的性质，但在实际的应用中，并不具有很强的分类能力。这主要是因为具有旋转不变性的$LBP^{ri}_{P,R}$的不同模式的出现频率差异非常大造成的，其中有些特定的LBP模式出现频率达90\%以上，大大超过其它模式的出现频率。即模式中对应二进制串0和1的跳变次数为0或者只有两次跳变，这些特定的 LBP 模式被称为等价模式(Uniform LBP)。而对应的非等价模式，即为模式中对应二进制串0和1的跳变次数大于两次\supercite{Marcel2006On}。 如图\ref{fig_lbp_3}，给出了等价模式和非等价模式的例子。
\begin{figure}[h] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_lbp_3.eps}
  \bicaption{等价模式与非等价模式示例~\label{fig_lbp_3}}{Examples of uniform and nonuniform patterns}
\end{figure}
采用了等价模式后，二进制模式大大减少，模式的数量从最开始的$2^P$种减少到了$P(P-1)+2$种。实验表明，等价模式的LBP算子不受图像旋转和平移的影响，能够有效地表达纹理特征，又能起到降维的作用，并且对暗点、亮点、平滑区域、边缘等也具有较好的描述能力。

\subsection{HOG特征}
HOG(Histogram of Oriented Gradient)特征由Navneet Dalal和Bill Triggs于2005年提出\supercite{Dalal2005Histograms}，应用于行人检测问题。在该特征被提出后，同样在物体检测(Object Detection)研究中得到了应用。由于HOG特征在Object Detection领域取得了巨大的成功，它逐渐被扩展用于图像处理和模式识别的其他领域，比如：行为分析，场景分类，图像检索等等。HOG特征有很多优点，其本质在于在一副图像中，局部目标的表象和形状能够被梯度或边缘的方向密度分布很好地描述。首先，由于HOG是在图像的局部方格单元上操作，所以它对图像几何和光学的形变都能保持很好的不变性，这两种形变只会出现在更大的空间领域上。其次，在粗的空域抽样、精细的方向抽样以及较强的局部光学归一化等条件下，只要行人大体上能够保持直立的姿势，可以容许行人有一些细微的肢体动作，这些细微的动作可以被忽略而不影响检测效果。因此HOG特征是特别适合于做图像中的人体检测的。目前，学术界将HOG特征分为HOG和FHOG这两种，下面将分别介绍。

（1）原始HOG特征

对图片计算原始的HOG特征包括了梯度的计算，块（Block）和细胞（Cell）的分割，归一化特征权重和全局扫描图像这四个部分，下面将分别介绍这四个部分。

梯度计算。某像素点$(x,y)$点的梯度包括水平方向梯度$G_x$和垂直方向梯度$G_y$。其由公式\ref{equ_hog_Gx} 和公式\ref{equ_hog_Gy} 分别确定。最常用的方法是：首先用$[-1,0,1]$梯度算子对原图像做卷积运算，得到$x$方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用$[1,0,-1]^T$梯度算子对原图像做卷积运算，得到$y$方向（竖直方向，以向上为正方向）的梯度分量gradscaly。然后再用以上公式计算该像素点的梯度大小和方向。
\begin{equation}
G_x(x,y)=H(x+1,y)-H(x-1,y)
\label{equ_hog_Gx}
\end{equation}
\vspace{-4ex}
\begin{equation}
G_y(x,y)=H(x,y+1)-H(x,y-1)
\label{equ_hog_Gy}
\end{equation}

其中，$H(x,y)$表示在像素点$(x,y)$处的像素值。求导操作不仅能够捕获轮廓，人影和一些纹理信息，还能进一步弱化光照的影响。根据梯度值的计算，可以得到图像中像素点(x,y)的梯度大小和方向分别为：
\begin{equation}
G(x,y)=\sqrt{G_x(x,y)^2+G_y(x,y)^2}
\label{equ_hog_am}
\end{equation}
\vspace{-3ex}
\begin{equation}
\alpha (x,y)=tan^{-1}(\frac{G_y(x,y)}{G_x(x,y)})
\label{equ_hog_direc}
\end{equation}

Block和Cell。计算出来图像所有像素点的梯度之后，需要做进一步的梯度统计，用到的统计单元就是Block和Cell，它们之间的对应关系如图\ref{fig_hog}所示：
\begin{figure}[ht] \centering
  \includegraphics[width=.4\textwidth]{figure/fig_hog.eps}
  \bicaption{Block和Cell的关系~\label{fig_hog}}{Relationship between Block and Cell}
\end{figure}
可以看出，一个Block实际上是由若干个Cell组成的，每个Cell其实是统计出来的基于方向的梯度直方图。梯度直方图又可以分为无向直方图$B_1$（Contrast Insensitive）和有向直方图$B_2$（Contrast Sensitive）：
\begin{equation}
B_1(x,y)=round(\frac{p\theta(x,y)}{\pi})mod~p
\label{equ_hist}
\end{equation}
\vspace{-3ex}
\begin{equation}
B_2(x,y)=round(\frac{p\theta(x,y)}{2\pi})mod~p
\label{equ_hog_hist2}
\end{equation}
这里统一使用$B$来表示$B_1$和$B_2$。在图\ref{fig_hog}中，如果计算的是无向直方图(Contrast Insensitive)，则$0\circ-360\circ$被平均分成了8份（p=8），$0^{\circ}-22.5^{\circ}$和$180^{\circ}-202.5^{\circ}$可以被视为一个通道，以此类推，这样的话，每个通道占用$45^{\circ}$。如果计算的是有向直方图(Contrast Sensitive)，则$0^{\circ}-360^{\circ}$被平均分了16份$(p=16)$，每个通道占用$22.5^{\circ}$。则位于$(x,y)$处的方向梯度特征向量为：
\begin{equation}
F(x,y)_b=\left\{\begin{matrix}
G(x,y), & if~b=B(x,y)\\
0,      & otherwise
\end{matrix}\right.
\label{equ_hog_vec}
\end{equation}
其中，$b$为直方图任意一个通道，即$b\in\left \{ 0,...,p-1 \right \}$。$p$为总通道数。Cell中每个像素点的梯度方向落入某个通道区域，则它对应的梯度大小被加入直方图的对应块。即对Cell中所有$(x,y)$的方向梯度特征向量$F(x,y)$求和。在实际应用中，一般采用9个通道的无向直方图统计$(p=9)$，并且每一个Block包含$2\times2=4$个Cell。

Block归一化及全局扫描。Block中4个Cell统计得到直方图存在尺度不一致的情况，所以需要根据每个Cell各自的权重进行归一化，常用的归一化手段有：$L1-norm$，$L2-norm$，$L1-sqrt$和$L2-Hys$。由于局部光照的变化以及前景-背景对比度的变化，使得梯度强度的变化范围非常大。归一化能够进一步地对光照、阴影和边缘进行压缩。通过将各个细胞单元组合成大的、空间上连通的区间（blocks），一个block内所有cell的特征向量串联起来便得到该block的HOG特征。这些区间是互有重叠的，这就意味着：每一个单元格的特征会以不同的结果多次出现在最后的特征向量中。我们将归一化之后的块描述符（向量）就称之为HOG描述符。区间有两个主要的几何形状――矩形区间（R-HOG）和环形区间（C-HOG）。R-HOG区间大体上是一些方形的格子，它可以有三个参数来表征：每个区间中细胞单元的数目、每个细胞单元中像素点的数目、每个细胞的直方图通道数目。那么最终的特征维数计算如下：最终的HOG特征，实际上是由很多个以Block为计算单位得到的特征向量串联而成，Block以一个Cell的大小为跨度在Cell-Map上全局扫描，得到的特征向量加入末尾，如图\ref{fig_hog_vec2}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.5\textwidth]{figure/fig_hog_vec2.eps}
  \bicaption{通过全局扫描得到HOG特征向量~\label{fig_hog_vec2}}{HOG vector by Global Scan}
\end{figure}
样本图像分割为若干个像素的单元（cell），把梯度方向平均划分为9个区间（bin），在每个单元里面对所有像素的梯度方向在各个方向区间进行直方图统计，得到一个9维的特征向量，每相邻的4个单元构成一个块（block），把一个块内的特征向量联起来得到36维的特征向量，用块对样本图像进行扫描，扫描步长为一个单元，最后将所有块的特征串联起来，就得到了人体的特征。例如，对于$64\times128$的图像而言，每$8\times8$的像素组成一个cell，每$2\times2$个cell组成一个块，因为每个cell有9个特征，所以每个块内有$4\times9=36$个特征，以8个像素为步长，那么水平方向将有7个扫描窗口，垂直方向将有15个扫描窗口。也就是说，$64\times128$的图片，总共有$36\times7\times15=3780$个特征。

（2）FHOG特征\supercite{Felzenszwalb2008A,Felzenszwalb2010Object}

FHOG是原始HOG特征的一个重要变形，由美国芝加哥大学的Felzenszwalb等人提出，它被验证在目标检测任务中中某些类别的检测效果比原始HOG更好，并在目标检测，特别是行人、人脸检测当中得到广泛应用。FHOG和HOG最大的区别在于前者取消了Block的概念，对于一张输入大小为w$\times$h的图片，直接进行Cell的切分，得到一张基于Cell的图$C$，假设Cell的宽高都为$k$个像素，则$C(i,j)$满足：
\begin{equation}
0\leq i \leq \left\lfloor \frac{w-1}{k} \right\rfloor
\label{equ_fhog1}
\end{equation}
\vspace{-3ex}
\begin{equation}
0\leq j \leq \left\lfloor \frac{h-1}{k} \right\rfloor
\label{equ_fhog2}
\end{equation}
要将原始图像中的每个点$(x,y)$的方向梯度特征计算后相加到相应的$C(i,j)$中，具体的步骤和原始HOG梯度计算一致，其中$(i,j)$和$(x,y)$服从如下的关系：
\begin{equation}
i=\left\lfloor \frac{x}{k} \right\rfloor
\label{equ_fhog3}
\end{equation}
\vspace{-3ex}
\begin{equation}
j=\left\lfloor \frac{y}{k} \right\rfloor
\label{equ_fhog4}
\end{equation}
在FHOG中，每个$C(i,j)$对应四种不同的归一化因子，每个归一化因子记做$N_{\delta,\gamma}(i,j)$，且$\delta,\gamma\in\left \{ -1,1 \right \}$，则有：
\begin{equation}
N_{\delta,\gamma}(i,j)=\sqrt{||C(i,j)||^2+||C(i+\delta,j)||^2+||C(i,j+\gamma)||^2+||C(i+\delta,j+\gamma)||^2}
\label{equ_fhog5}
\end{equation}
每一个归一化因子的含义是$C(i,j)$所对应的Block的“梯度能量”，因为一个Cell对应四个Block，所以也对应四个“梯度能量”（归一化因子），每个因子都是对包含$(i,j)$在内的4个cell组成的块block的梯度能量的度量。在FHOG中，除了Cell图$C$之外，增加了另外一个Cell图，记作图$D$。图$C$和图$D$的区别在于图$C$统计无向的直方图(Contrast Insensitive)，图$D$统计有向的直方图（Contrast Sensitive）。经过4个不同方向的归一化因子归一化之后，图$C$可以计算得到$H_1(i,j)$，它是一个$4\times9$的特征矩阵，图D可以计算得到$H_2(i,j)$，它是一个$4\times18$的特征矩阵，这里将$H_1(i,j)$和$H_2(i,j)$进行组合得到$H(i,j)$:
\begin{equation}
H(i,j)=[H_1(i,j),H_2(i,j)]
\label{equ_fhog6}
\end{equation}
可见，H是$4\times27$维的矩阵，令:
\begin{equation}
V=\left\{ u_1,...,u_9 \right \} \cup \left \{ u_{10},...,u_{27} \right \}\cup \left \{ v_1,...,v_4 \right \}
\end{equation}
其中：
\begin{equation}
u_k(i,j)=\left\{\begin{matrix}
1, & if~j=k\\
0, & otherwise
\end{matrix}\right.
\label{equ_fhog7}
\end{equation}
\begin{equation}
v_k(i,j)=\left\{\begin{matrix}
1, & if~i=k\\
0, & otherwise
\end{matrix}\right.
\label{equ_fhog8}
\end{equation}
如上述定义，$u_k$和$v_k$也都是$4\times27$维的矩阵，FHOG则为$V$中所有的元素和$H$点乘求和的结果。$V$中有31个矩阵元素，所以得到的FHOG是一个31维的特征向量。它的前27维对应不同的方向通道（9个Contrast Insensitive和18个Contrast Sensitive），剩余$4$个通道则是当前Cell在$4$个不同Block中的能量和。在PASCAL VOC数据库上实验表明，用FHOG做特征提取的算法在很多应用中效果比原始HOG特征效果更好。

\subsection{非手工设计特征}

上述几种特征都是人类手工设计的特征，是人类智慧的结晶。深度学习是近年来人工智能领域取得的重要突破。深度学习的本质是通过多层非线性变换从大数据中自动学习不同抽象层次的特征，从而替代手工设计。深层的结构使深度学习具有极强的表达能力和学习能力，尤其擅长提取复杂的全局特征和上下文信息，而这是浅层模型难以做到的。传统的机器学习技术在处理未加工过的数据时，体现出来的能力是有限的。几十年来，想要构建一个模式识别系统或者机器学习系统，需要一个精致的引擎和相当专业的知识来设计一个特征提取器，把原始数据（如图像的像素值）转换成一个适当的内部特征表示或特征向量，子学习系统，通常是一个分类器，对输入的样本进行检测或分类。特征表示学习是一套给机器灌入原始数据，然后能自动发现需要进行检测和分类的表达的方法。深度学习就是一种特征学习方法，把原始数据通过一些简单的但是非线性的模型转变成为更高层次的，更加抽象的表达。通过足够多的转换的组合，非常复杂的函数也可以被学习。对于分类任务，高层次的表达能够强化输入数据的区分能力，同时削弱不相关因素。比如，一副图像的原始格式是一个像素数组，那么在第一层上的学习特征表达通常指的是在图像的特定位置和方向上有没有边的存在。第二层通常会根据那些边的某些排放而来检测图案，这时候会忽略掉一些边上的一些小的干扰。第三层或许会把那些图案进行组合，从而使其对应于目标的某部分。随后的一些层会将这些部分再组合，从而构成待检测目标。深度学习的核心方面是，上述各层的特征都不是利用人工工程来设计的，而是使用一种通用的学习过程从数据中学到的。

深度学习正在取得重大进展，解决了人工智能界手工设计的特征所带来的局限性的问题。它已经被证明，它能够擅长发现高维数据中的复杂结构，因此它能够被应用于科学、商业和政府等领域。除了在图像识别、语音识别等领域打破了纪录，它还在另外的领域击败了其他机器学习技术，包括预测潜在的药物分子的活性、分析粒子加速器数据、重建大脑回路、预测在非编码DNA突变对基因表达和疾病的影响。也许更令人惊讶的是，深度学习在自然语言理解的各项任务中产生了非常可喜的成果，特别是主题分类、情感分析、自动问答和语言翻译。我们认为，在不久的将来，深度学习将会取得更多的成功，因为它需要很少的手工工程，并很容易受益于可用计算能力和数据量的增加。目前正在为深度神经网络开发的新的学习算法和架构更会加速这一进程。
\section{基于类Haar特征的AdaBoost人脸检测}
\subsection{基于Adaboost学习算法}
基于AdaBoost的学习算法有两个目的，一是从大量类Haar特征中选择出最优的一部分特征，二是将挑选出的特征用于训练有效的分类器。由于并不是每一个类Haar特征都能很好的表现人脸灰度分布特点，因此如何挑选出少量的最优的特征来组成有效的分类器成为我们要解决的主要问题。

每一个分类器对应一个矩形特征，通过将一个复杂的分类器拆分成简化的弱分类器，然后将弱分类器集成层叠组合形成有效的强分类器，从而将候选图像子窗口的人脸和非人脸区分开。具体的训练步骤如下所示：

\begin{itemize}
  \item 给定样本图像$(x_1,y_1),...,(x_n,y_n)$，其中$y_i = 0,1$分别代表负样本和正样本；
  \item 初始化权重：
    \begin{equation}
	w_{1,i} = \left\{
        \begin{array}{cc}
          \frac1{2m} & y_i = 0 \\
          \frac1{2l} & y_i = 1
        \end{array}
      \right.
    \end{equation}
        其中$m$表示负样本的数目，$l$表示正样本的数目；
  \item 对于$t = 1,...,T$:
    \begin{enumerate}
      \item 归一化权重：
        \begin{equation}
          w_{t,i} \leftarrow \frac{w_{t,i}}{\sum_{j=1}^n w_{t,j}}
        \end{equation}
            其中$w_t$是概率分布；
      \item 对于每个特征j训练分类器$h_j$，每个分类器有且只对应一种特征，分类器错误率是
        \begin{equation}
          \varepsilon_j = \sum_i w_i |h_j(x_i) - y_i|
        \end{equation}
      \item 选择错误率$\varepsilon_t$最小的分类器$h_t$；
      \item 更新权重：
        \begin{equation}
          w_{t+1,i} = w_{t,i}\beta_t^{1-e_i}
        \end{equation}
        其中，$\beta_t = \frac{\varepsilon_t}{1-\varepsilon_t}$如果样本$x_i$ 被正确分类$e_i = 0$，反之，$e_i = 1$；
    \end{enumerate}
  \item 最后得到强分类器为：
    \begin{equation}
      h(x) = \left\{
      \begin{array}{cc}
        1 & \sum_{t=1}^T \alpha_t h_t(x) \geq \frac{1}{2}\sum_{t=1}^T \alpha_t\\
        0 & 其他
      \end{array}\right.
    \end{equation}
        其中$\alpha_t = \lg\frac{1}{\beta_t}$
\end{itemize}

\subsection{级联分类器}
基于AbaBoost级联分类器如图\ref{fig_AdaBoostcascade}所示。层叠的分类器每一层都是由若干弱分类器组成的强分类器，首先采用较少的特征放在前级分类器，即弱分类器较少，以排除大部分非人脸区域，能够通过几乎全部的人脸；后级分类器采用更多的特征，即强分类器由更多的弱分类器组成，检测上一层通过的子窗口，加强检测人脸的区域。随着层数的增加，弱分类器的数量也在增加，同时从上一层过滤下来的子窗口数量在减少，从而能够保证较高的检测速度。这里的待测图像，一般将其按比例缩放进行归一化，每个图像的尺寸为$24\times24$像素的子窗口，依次判别是人脸还是非人脸。
\begin{figure}[!h] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_AdaBoost_Cascade.eps}
  \bicaption[基于AdaBoost级联分类器结构]{基于AdaBoost级联分类器结构~\label{fig_AdaBoostcascade}}{Structure of AdaBoost-based cascade classifiers}
\end{figure}
\section{基于级联可变型部件模型的人脸检测}
\subsection{特征金字塔的构建}
在自然环境下，目标图像可能具有不同的尺寸，这就要求滤波器能够在不同的分辨率下对图像进行扫描检测，从而得到最完备的检测结果，如图\ref{fig_hog_pyramid}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.4\textwidth]{figure/fig_hog_pyramid.eps}
  \bicaption[图像金字塔示例]{图像金字塔示例 ~\label{fig_hog_pyramid}}{Illustration of Image Pyramid }
\end{figure}
因此，在特征提取过程中，采用了特征金字塔的形式。对待检测图片进行尺寸的变换，构造图像的特征金字塔，然后到于每一层的图像使用检测器进行检测。通过对图像金字塔的分层依次检测，可以保证检测结果不会因为人脸的尺寸不同而产生错误，也可保证人脸大小不同导致的漏检。由于局部图像的边缘和关照变化能够使用梯度方向直方图来描述，这样，特征金字塔的结构就可以对各尺度下的特征结构进行编码。也就是说一幅图像的 HOG 特征是由多层的特征金字塔组成的。特征金字塔的使用保证了可变形部件模型对多角度目标的检测。上一章所述FHOG特征能够很好的勾勒出物体对象的轮廓，对微小形变和光照变化有很好的鲁棒性，不仅适合所涉及到的非生物目标的特征表示，也很适合来表示人脸。如下图\ref{fig_hog_face}所示：
\begin{figure}[!ht] \centering
  \includegraphics[width=.6\textwidth]{figure/fig_hog_face.eps}
  \bicaption{以FHOG 特征表示的人脸图像模型 ~\label{fig_hog_face}}{Face model represented by FHOG descriptor}
\end{figure}
\subsection{DPM人脸检测模型}
可变性部件模型(Deformable Part Model )是由Felzenszwalb\supercite{Felzenszwalb2010Object}等人提出的基于滑动窗口中各部件以及各部件之间关系的检测模型。该方法对于通过可变性部件进行建模的配置提供了一个优良的框架。可变性部件模型基于Dalal-Triggs检测器，使用HOG特征和HOG多尺度特征金字塔，引入了可变性部件,提高了模型对于物体类内多样性变化的适用性。DPM模型使用多尺度HOG特征金字塔来描述物体的特征，在各组金字塔的每一层中提取特征，也就是提取了多尺度的待检测物体特征,这样就适应了待检测目标在一定程度上的尺度伸缩变化。可变性部件模型除了包括一个粗粒度的模板来覆盖整个对象，还包括高分辨率的部件模板来对各部件进行匹配。在训练过程中，将框定待检测对象的图片作为正样本，将每一个对象的各部件的位置作为一个潜在变量。可变形部件模型(Deformable Part Model)由三部分组成：
\begin{itemize}
\item(1) 一个较为粗糙的，覆盖整个目标的全局根模版(或叫做根滤波器)。
\item(2) 几个高分辨率的部件模版(或叫做部件滤波器)。
\item(3) 部件模版相对于根模版的空间位置。
\end{itemize}

首先要计算一个HOG金字塔：通过计算标准图像金字塔中每层图像的特征得到特征金字塔，HOG金字塔中每一层的的最小单位是细胞单元(cell)。滤波器(模版)就是一个权重向量，一个$w\times h$大小的滤波器$F$是一个含$w\times h\times9\times4$个权重的向量($9\times4$是一个HOG细胞单元的特征向量的维数)。所谓滤波器的得分就是此权重向量与HOG金字塔中$w \times h$大小子窗口的HOG特征向量的点积(DotProduct)。而检测窗口的得分是根滤波器的分数加上各个部件的分数的总和，每个部件的分数是此部件的各个空间位置得分的最大值，每个部件的空间位置得分是部件在该子窗口上滤波器的得分减去变形花费。

假设H是HOG金字塔，$p = (x, y, l)$ 表示金字塔第一层 $(x, y)$ 位置的一个细胞单元。$\varphi(H, p, w, h)$是将金字塔$H$中以$p$为左上角点的$w\times h$大小子窗口的HOG特征串接起来得到的向量。所以，滤波器$F$在此检测窗口上的得分为：$F\varphi(H, p, w, h)$。此后，在不引起歧义的情况下，我们使用$\varphi(H,p)$代表$\varphi(H, p, w, h)$。所以，含$n$个部件的模型可以通过根滤波器$F_0$和一系列部件模型$(P_1,..., P_n)$来定义,其中$P_i = (F_i, v_i, s_i, a_i, b_i)$。$F_i$是第$i$个部件的滤波器；$v_i$和$s_i$都是二维向量，都以细胞单元为单位，$v_i$指明第$i$个部件位置的矩形中心点相对于根位置的坐标，$s_i$是此矩形的大小；$a_i$和$b_i$也都是二维向量，指明一个二次函数的参数，此二次函数用来对第$i$个部件的每个可能位置进行评分。

这里，使用$\beta$表示模型的参数，$F_0$表示根滤波器的参数，$F_1,...,F_7$为各部件的参数，$d_1,...,d_n$为各部件的形变值，$b$为偏移值，则模型的参数向量可以表示为：
\begin{equation}
\beta=(F_0,F_1,...F_n,d_1,...d_n,b)
\end{equation}
在进行检测时，使用了滑动窗口的方法，检测对象模型包括一个全局的根滤波器和很多部件模型。每一个部件模型都制定了一个具体的空间模型和部件滤波器。空间模型定义了对于一个部件相对于检测窗口允许变化的范围空间以及在该位置的变形代价。待检测窗口的得分是根滤波器的得分加上各部分最大重合部分的得分减去变形代价。若检测窗口的得分高于阈值,则说明检测窗口中包含待检测物体，否则不包含。令$\varphi(x,y)$为检测窗口对应的图像特征，$x$表示检测窗口的位置，$z$表示各部件的位置，那么该图像的最终得分如下:
\begin{equation}
score(x)=\max \limits_{z\in Z(x)}\beta\cdot \varphi(x,z)
\label{equ_dpm_score}
\end{equation}
其中，参数$\beta$由训练得出。待检测窗口的得分是根滤波器的得分加上各部分最大重合部分的得分减去变形代价，这与传统的基于部件的模型相似。根滤波器和部件滤波器都是由计算HOG特征与权值之间的点积得到。跟滤波器等同于Dalal-Triggs模型，计算各部件的特征的分辨率是根滤波器的两倍。

本文提到的模型是固定规模的,通过在图像金字塔上检测对象，从而达到对不同分辨率进行检测的效果。高得分的根位置定义了一次检测，产生高得分根位置的部件位置定义了一个完整的目标假设。通过定义每个根位置的综合得分(overall score)，可以检测目标的多个实例(假设每个根位置上最多一个实例)。这种方法与滑动窗口检测器有关联，因为可以认为$score(p_0)$ 是检测窗口在指定根位置的得分。通过使用动态规划和广义距离变换(min-convolution)来计算部件的最优位置(是根位置的函数)，此方法非常高效，花费$O(nk)$时间计算一个滤波器的响应值，$n$是模型中部件的个数，$k$是特征金字塔中位置的总数，详细的解释在文献\parencite{Felzenszwalb2004Distance}和文献\parencite{Felzenszwalb2005Pictorial}中有详细的解释。

\subsection{Structured SVM模型训练}
（1）隐藏变量SVM――Latent SVM

在模型的训练过程中，引入了专门为弱监督设计的隐支持向量机(Latent Support Vector Machine, LSVM)。考虑一个分类器，在 LSVM 中每个样本$x$的得分可以使用下面的形式表示：
\begin{equation}
f_{\beta}(x)=\max \limits_{z\in Z(x)}\beta\cdot \varphi(x,z)
\label{equ_lsvm_score}
\end{equation}
这里$\beta$是模型参数向量，$z$是隐藏变量。集合$Z(x)$定义了样本$x$所有可能的隐藏变量值。通过对此得分值进行阈值化，可以获得样本$x$的二分类类标。类比经典SVM算法，我们使用带类标的样本集$D = (<x1, y1>, ..., <xn,yn>), yi\in{-1, 1}$来训练参数$\beta$，优化目标函数为：
\begin{equation}
L_D(\beta)=\frac{a}{b}||\beta||^2+C\sum_{i=1}^{n}\max(0,1-y_if_{\beta}(x_i))
\label{equ_lsvm_optims}
\end{equation}
其中$\max(0,1-y_if_{\beta}(x_i))$是标准铰链损失函数（hinge loss），常数$C$控制正则项的相对权重。如果每个样本的隐藏变量有唯一可能值$|Z(x_i)|=1$，则$f_{\beta}$是$\beta$的线性函数，此时变为线性SVM问题，这是LSVM的一个特例。

（2）半凸规划

LSVM最终是一个非凸规划(non-convex)问题。然而，下面所讨论的情况下LSVM是半凸规划(semi-convexity)问题，一旦将隐藏信息指定给正样本则训练问题变为凸规划问题。几个凸函数的最大值问题是凸规划问题。在线性SVM中，有:
\begin{equation}
f_{\beta}(x)=\beta\cdot \varphi(x)
\label{equ_lsvm_convex}
\end{equation}
是$\beta$的线性函数，此时铰链损失函数对每个样本都是凸的，因为它是两个凸函数的最大值。注意到公式\ref{equ_lsvm_score}中定义的$f_{\beta}$是一系列函数的最大值，而这些函数都是$\beta$的线性函数，因此$f_{\beta}$是$\beta$的凸函数。所以当$y_i = -1$时，两个函数$f(x)=0$和$f(x)=1-y_if_{\beta}(x_i)$都是$\beta$的凸函数，所以铰链损失函数$\max(0,1-y_if_{\beta}(x_i))$是$\beta$的凸函数。也就是说，只有当样本为负样本时，损失函数是$\beta$的凸函数。我们将损失函数的这一性质叫做半凸(semi-convexity)。对于正样本$(yi= 1)$来说，LSVM的铰链损失函数不是凸函数，因为它是一个凸函数$f(x)= 0$和一个凹函数$f(x)=1-y_if_{\beta}(x_i)$的最大值。但是，当LSVM的正样本的隐藏变量具有唯一可能的取值时，$f_{\beta}(x_i)$是$\beta$的线性函数，因此损失函数是$\beta$的凸函数，再加上半凸性质，公式\ref{equ_lsvm_optims}变为凸规划问题。

（3）模型训练步骤

模型的训练过程主要包括以下几个步骤：

1）初始化根滤波器。初始化根滤波器的时候首先根据训练图片的标记确定根滤波器的规模，然后使用支持向量机(SVM)来训练根滤波器$F_0$，在这个过程中没有使用到隐变量。

2）更新根滤波器。这个过程中，对于训练集中的每一个样本使用上一步确定的根滤波器寻找响应最大并且和原有标记有明显覆盖的位置，并以此位置更新训练图片的框标记；然后使用新位置标记的样本以及随机选取的负样本来更新根滤波器$F_0$。

3）初始化部件滤波器。在确定的根滤波器的位置上，贪婪的选择得分最大的区域作为部件滤波器的位置。

4）更新滤波器。使用不断更新的正负训练样本来训练、更新滤波器。在这里使用的正负训练样本具有如下的特点：正样本选择在训练中的高分区域占到标记的50\%以上的样本；负样本选择在旧滤波器的检测中得分很高的负样本。使用上述样本来训练新的模型，并不断地更新训练样本，如此多次迭代(10 次)得到最终的模型。

以上是使用隐支持向量机训练可变形部件测过程，通过不断地迭代以及样本更新，最终可以得到我们需要的可变形部件模型。
%\subsection{算法复杂度分析}
\section{本章小结}
本章主要介绍了人脸检测的研究概述和本文所采用的人脸检测的方法，另外介绍了在人脸检测和识别当中用到的主流的特征。在实际的智能监控工程应用系统当中，人脸检测是非常重要的预处理部分，其不仅考虑到多视角下的检测率和误检率，而且要保证检测的实时性。Haar~特征是人脸检测当中最初应用的特征，基于~LBP~的~Adaboost~人脸检测性能比~Haar~特征在准确率和误检率上都有很大的提升，这得益于特征本身的鲁棒性，然而在处理多视角中显得不足，而基于DPM模型的人脸检测因其本身模型的适应性以及FHOG特征金字塔模型的有效性，使得多姿态人脸检测能够保证很高的检测率和很低的误检率，但是速度较LBP-Adaboost模型较慢，这部分可通过工程上的实现，比如并行加速、指令集优化来弥补。详情在实验结果与分析部分会给出介绍。