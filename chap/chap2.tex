% vim:ts=4:sw=4
% Copyright (c) 2014 Casper Ti. Vector
% Public domain.
\chapter{复杂姿态下人脸检测}
人脸检测(Face Detection)的目的是为了确定图像中人脸的位置、大小和数量，更加精细的人脸检测还包括人脸的朝向及姿态。人脸检测是所有人脸图像分析的预处理过程，经过多年发展，人脸检测在检测准确率和实时性方面都取得了很大的突破，研究者们针对各种复杂场景也提出了大量的人脸检测算法。本章将从人脸检测研究概述、人脸检测和识别当中的特征、人脸检测方法三个方法进行论述。在人脸检测方法当中，主要介绍经典的基于Haar Adaboost的方法和本文采用的级联可变形部件模型人脸检测方法，并在后续的实验章节对两种方法进行了对比。
\section{人脸检测研究概述}
人脸检测是人脸识别的基础，如果人脸检测出现错误，后续的人脸识别基本无法进行。衡量人脸检测算法的好坏主要有以下三个指标：（1）召回率，即正确检测到的人脸数量与数据库中总的人脸数量之比。这个指标反映了检测器可以正确找到多少人脸。（2）精确度，即在所有输出的人脸中，正确的人脸所占的比例。这个指标反映了检测器检出结果的可靠程度。（3）稳定度，即当人脸在图片中的位置和大小发生变化或者人脸保持一定姿态不动时，输出的人脸位置和大小也需要相对于真实人脸保持不变，即检测的窗口不能发生闪烁现象。越稳定的人脸检测结果对于后序的人脸校准操作越有利。这三个指标越高，人脸检测算法越好。到目前为止，最具有里程碑意义的人脸检测算法是文献\parencite{viola2001rapid}，它奠定了现代人脸检测算法的基础。为了解决文献\parencite{viola2001rapid}不能很好的处理多角度的问题，随后也出现了许多针对多角度人脸检测的经典算法\supercite{Li2002Statistical,Wu2004Fast,Huang2007High,Li2011Face,li2014efficient}。有关人脸检测技术的发展，读者可以参考综述文献
\parencite{surveyface}。

人脸检测早在上世纪70年代就已经有人开始研究，然而受当时落后的技术条件和有限的需求所影响，直到上世纪90年代，人脸检测技术才开始加快向前发展的脚步，在新世纪到来前的最后十年间，涌现出了大量关于人脸检测的研究工作，这时期设计的很多人脸检测器已经有了现代人脸检测技术的影子，例如可变形模板的设计（将人脸按照五官和轮廓划分成多个相互连接的局部块）、神经网络的引入（作为判断输入是否为人脸的分类模型）等。这些早期的工作主要关注于检测正面的人脸，基于简单的底层特征如物体边缘、图像灰度值等来对图像进行分析，结合关于人脸的先验知识来设计模型和算法（如五官、肤色），并开始引入一些当时已有的的模式识别方法。

虽然早期关于人脸检测的研究工作离实际应用的要求还有很远，但其中进行检测的流程已经和现代的人脸检测方法没有本质区别。给定一张输入图像，要完成人脸检测这个任务，我们通常分成三步来进行：
\begin{itemize}
\item 选择图像上的某个（矩形）区域作为一个观察窗口；
\item 在选定的窗口中提取一些特征对其包含的图像区域进行描述；
\item 根据特征描述来判断这个窗口是不是正好框住了一张人脸。
\end{itemize}

检测人脸的过程就是不断地执行上面三步，直到遍历所有需要观察的窗口。如果所有的窗口都被判断为不包含人脸，那么就认为所给的图像上不存在人脸，否则就根据判断为包含人脸的窗口来给出人脸所在的位置及其大小。

那么，如何来选择我们要观察的窗口呢？所谓眼见为实，要判断图像上的某个位置是不是一张人脸，必须要观察了这个位置之后才知道，因此，选择的窗口应该覆盖图像上的所有位置。显然，最直接的方式就是让观察的窗口在图像上从左至右、从上往下一步一步地滑动，从图像的左上角滑动到右下角――这就是所谓的滑动窗口范式，你可以将它想象成是福尔摩斯（检测器）在拿着放大镜（观察窗口）仔细观察案发现场（输入图像）每一个角落（滑动）的过程。其滑动窗口的机制如下图\ref{fig_sliding_pyramid}.~(a)所示。
\begin{figure}[!h] \centering
  \centerline{\includegraphics[width=12.5cm]{./figure/fig_sliding_pyramid.eps}}
  \bicaption[滑动窗口]{(a)~滑动窗口~(b)~图像金字塔~\label{fig_sliding_pyramid}}{(a)~Sliding window~(b)~Image pyramid}
\end{figure}

对于观察窗口，还有一个重要的问题就是：窗口应该多大？我们认为一个窗口是一个人脸窗口当且仅当其恰好框住了一张人脸，即窗口的大小和人脸的大小是一致的，窗口基本贴合人脸的外轮廓。即使是同一张图像上，人脸的大小不仅不固定，而且可以是任意的，这样怎么才能让观察窗口适应不同大小的人脸呢？一种做法当然是采用多种不同大小的窗口，分别去扫描图像，但是这种做法并不高效。换一个角度来看，其实也可以将图像缩放到不同的大小，然后用相同大小的窗口去扫描――这就是所谓的构造图像金字塔的方式。图像金字塔这一名字非常生动形象，将缩放成不同大小的图像按照从大到小的顺序依次往上堆叠，正好就组成了一个金字塔的形状。如图\ref{fig_sliding_pyramid}.~(b)所示。通过构建图像金字塔，同时允许窗口和人脸的贴合程度在小范围内变动，就能够检测到不同位置、不同大小的人脸了。另外需要一提的是，对于人脸而言，通常只用正方形的观察窗口，因此不需要考虑窗口的长宽比等问题了。

然而，上述方法并没有考虑侧脸或者人脸姿态形变比较严重的情况。有相关统计表明，在非限制场景下如家庭环境当中拍摄的照片当中，接近有75\%的人脸是非正脸照片。而在智能监控视频当中，由于摄像头位置和角度问题，这种情况更加严重，完全正脸的情况占的比重更小，因此研究者们针对多姿态的人脸也展开了一定的研究。大部分的方法都是针对不同角度的人脸训练不同的分类器。Schneiderman等人\supercite{schneiderman2004object}分别将人脸分为正面、左侧面、右侧面，并根据不同的人脸划分训练不同的分类器，检测时依次循环三个模型；Feraud等\supercite{Rapha1997A}提出了一种受限生成模型（Constrained Generative Model），并利用该模型构造了四个人脸检测器分别针对左右偏转$[0^\circ,20^\circ]$和$[20^\circ,40^\circ]$的人脸进行检测；Li等\supercite{Li2004Support}也是利用支持向量机（SVM）将人脸分为不同姿态进行检测和识别；针对多个模型进行多角度人脸检测会导致耗时严重的问题，Li等
\supercite{Zhang2002Multi}提出了一种Floatboost学习方法，其基本思想是将人脸训练样本分成几个较均匀的子视角类，然后训练一个“由粗到细”的金字塔型结构人脸检测器，从而实现了实时的多角度人脸检测。

另外，人脸检测作为一种特定类型目标的检测任务，一方面具有其自己鲜明的特点，需要考虑人脸这一目标的特殊性，另一方面其也和其它类型目标的检测任务具有一定的共性，能够直接借鉴在通用目标检测方法上的研究经验。目标检测任务作为一个分类问题，其不仅受益于计算机视觉领域相关技术的不断发展，在机器学习领域的研究进展同样也对目标检测任务具有推波助澜的作用。事实上，从2006年开始逐步蔓延开的深度学习大爆发给目标检测的研究带来了强劲的助推力，使得通用的目标检测以及各种特定类型目标的检测任务得到了跨越式地发展。

经过几十年的研究和发展，人脸检测取得了很大的进展，且在各个领域都有着广泛的应用，但是人脸检测问题还并没有被完全解决，复杂多样的姿态变化，千奇百怪的遮挡情况，捉摸不定的光照条件，不同的分辨率，迥异的清晰度，微妙的肤色差，各种内外因素的共同作用让人脸的变化模式变得极其丰富，而目前还没有检测器可以同时对所有的变化模式都足够鲁棒。

总结人脸检测多年的发展历程，我们可以发现人脸检测的发展某一方面也是人脸特征表示的发展。人脸检测的核心问题在于对人脸和非人脸的图片进行有区分力的分类，因而人脸特征表示至关重要。因此，在下文当中，本章首先介绍人脸检测过程当中常见的特征，然后介绍人脸检测领域经典的人脸检测方法以及我们自己采用的方法，并在后续的章节中进行实验对比及验证。
\section{人脸检测和识别中的特征}
人脸特征表示的好坏，直接关系到了人脸检测与识别的精度的高低。因此，如何得到具有表达力的人脸特征，就是人脸检测与识别最关键的问题。纵观30多年的人脸识别的研究历史，我们发现人脸识别技术的发展本质上也就是人脸特征的发展。特征提取的作用就是根据已知的人脸的位置信息，提取出对于人脸识别有利的信息,如面部区域、纹理结构等，而去掉和人脸识别无关的，如背景、噪声等信息。一个优秀的人脸特征需要满足以下两个要求：（1）该特征需要对不同人之间的细微区别十分敏感。（2）同时，该特征需要对人脸角度、光照、表情等变化具有一定的不变性。目前人脸识别技术中，运用的最多的特征有以下几种LBP\supercite{Ojala2002Gray}，SIFT\supercite{Lowe2004Distinctive}，HOG\supercite{Dalal2005Histograms}，Gabor\supercite{Liu2002Gabor}，LE\supercite{LE}等。这些特征在广泛的应用中均取得了不错的识别精度。目前，由于深度学习（deep learning）的发展，也有许多基于深度学习的算法将特征提取和特征学习融合到同一个框架中，其中包括：DeepFace\supercite{Taigman2014DeepFace}、DeepID\supercite{Sun2014Deep}、FaceNet\supercite{Schroff2015FaceNet}等。由于深度神经网络强大的拟合能力，这类方法在各种人脸识别问题中均取得了十分优秀的结果。但是由于这类方法网络结构复杂，模型参数一般都在百万量级。模型大小一般为几百兆，在实际使用中不太方便。另外，这类方法需要硬件支持并行计算，不适合手机或嵌入式系统上的人脸识别。因此，深度学习算法一般运用在云计算中。目前有许多公司提供基于深度学习的人脸云计算服务，例如:Face++、Microsoft、SenseTime、Tencent等。
\subsection{Haar-Like特征}
（1）Haar-Like特征简介

Haar-like特征最早是由Papageorgiou等人提出并应用于人脸表示，Viola和Jones在此基础上使用了3种类型4种形式的特征提出了一种新的人脸检测器，检测VJ人脸检测器。在人脸检测的过程中，需要AdaBoost级联分类器，分类器的训练则要在图像中选取一些简单特征，这些抽取的特征由各个矩形特征组成，称为Haar特征。Haar特征是计算机视觉领域一种常用的特征描述算子，基本Haar特征原型只有四种，而扩展的类Haar特征分为三类：边缘特征、线性特征和中心特征，它们组合成为特征模板。如图\ref{fig_haar}所示\supercite{ExtendHaar}。
\begin{figure}[!h] \centering
  \includegraphics[width=.6\textwidth]{figure/fig_haar.eps}
  \bicaption[类Haar特征]{类Haar特征~\label{fig_haar}}{Haar-like features}
\end{figure}

所谓Haar特征，其实就是在窗口的某个位置取一个矩形的小块，然后将这个矩形小块划分为黑色和白色两部分，并分别对两部分所覆盖的像素点（图像上的每个点称为一个像素）的灰度值求和，最后用白色部分像素点灰度值的和减去黑色部分像素点灰度值的和，得到一个Haar特征的值。Haar特征反映了局部区域之间的相对明暗关系，能够为人脸和非人脸的区分提供有效的信息，例如眼睛区域比周围的皮肤区域要暗，通过Haar特征就可以将这一特点表示出来。但是由于提取Haar特征时每次都需要计算局部区域内多个像素点灰度值之和，因此在速度上其并不快，为此VJ人脸检测器引入了积分图来加速Haar特征的提取。

（2）积分图的快速计算

积分图是一张和输入图像一样大的图，但其每个点上不再是存放这个点的灰度值，而是存放从图像左上角到该点所确定的矩形区域内全部点的灰度值之和。积分图所带来的好处是两方面的，一方面它使得每次计算局部区域像素点的灰度值之和仅需要做4次加减法，与局部区域的大小无关；另一方面它避免了在相同像素点上重复求和，只在最开始计算一次――相邻的窗口有很大的重叠部分，对应的Haar特征也会重叠，如果每次都重新计算像素点的灰度值之和，则重叠部分的计算是重复的。积分图极大地加速了Haar特征的提取，向快速的检测器迈出了第一步。积分图的表示方法对Haar特征的快速计算有重要意义。积分图表示方法如图\ref{fig_itegral}所示。
\begin{figure}[!h] \centering
  \includegraphics[width=.6\textwidth]{figure/fig_itegral.eps}
  \bicaption[积分图]{积分图~\label{fig_itegral}}{Integral image}
\end{figure}

在这个积分图像中，每一点的值表示图像中该点位置左上部分区域内的所有像素的灰度值积分。如公式(\ref{equ_integral})所示。
\begin{equation}
ii(x,y) = \sum_{x'\leq x,y'\leq y}i(x',y')
\label{equ_integral}
\end{equation}
其中$ii(x,y)$是图像中$(x,y)$点的像素灰度值积分，$i(x',y')$是图像中$(x',y')$点的像素灰度值。如果计算积分图像中某一区域的像素灰度值积分，则由该区域四个顶点对应的积分值作相应的加减运算得到。例如，区域D的积分$S_{D}$可由图像中1，2，3，4点的积分值$S_{1}$，$S_{2}$，$S_{3}$，$S_{4}$计算得到，即：
\begin{equation}
S_{D} = S_{4} + S_{1} - S_{2} -S_{3}
\end{equation}

图像中每点的积分值保存在内存中，计算某区域积分值变成了简单的加减运算，不必重新计算该区域像素和，计算消耗的时间是常量，所以不管图像尺寸如何，积分图表示方法可以降低特征值的计算复杂度。

\subsection{LBP特征}
（1）基本LBP

局部二元模式（Local Binary Pattern,~LBP）是一种用来描述图像局部纹理特征的算子。1996年，Ojala\supercite{Ojala2002Gray}等人提出了原始LBP算子，并用来提取图像的纹理特征，并且验证了它在纹理分类中的强大能力。由于其在纹理分类中优良的有效性及其计算简单，且对单调的灰度变化具有不变性等特点，由于LBP是整数特征，计算速度很快，常被普遍应用于人脸检测、人脸识别以及表情分析和背景建模等领域。一般来讲，基本的LBP算子定义为在$3\times3$的窗口内，以窗口中心像素为基准点，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，$3\times3$领域内的8个点可产生8比特（bit）的无符号数，即得到该窗口的LBP值，经过遍历每个像素点后，即可得到经过LBP算子之后的效果图，这种图纹理信息。如图\ref{fig_lbp_1}所示。
\begin{figure}[!h] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_lbp_1.eps}
  \bicaption[基本LBP算子示意图]{基本LBP算子示意图~\label{fig_lbp_1}}{Illustration of basic LBP}
\end{figure}

上述十进制的形式可以用一个8比特的一个字节来表示，其表达式为：
\begin{equation}
LBP(x_c,y_c)=\sum_{n=0}^{7}s(i_n-i_c)2^n
\label{equ_lbp}
\end{equation}
其中，对于像素点位置$(x_c,y_c)$，其对应的像素的值为$i_c$，并作为中心点位置，将有8个像素点$i_n(n=0,1,2...7)$对其依次环绕，左上角为第一个像素点。二值化处理函数定义为：
\begin{equation}
s(x)=\left\{\begin{matrix}
1 &  if &  x\geq 0\\
0 &  if &  x < 0
\end{matrix}\right.
\label{equ_lbp2}
\end{equation}
下图\ref{fig_lbp_img}展示了一张人脸图片经过LBP算子运算之后得到的图像。
\begin{figure}[h] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_lbp_img.eps}
  \bicaption{原始图像（左）经LBP算子处理后的图像（右）~\label{fig_lbp_img}}{Original image (left) processed by the LBP operator (right).}
\end{figure}

（2）多尺度LBP

Ojala等人在后续工作中又对基本的LBP算子进行了拓展，使得邻域的范围不单局限在$3\times3$ 的邻域，主要通过不同半径所构成的圆形邻域表示，如图\ref{fig_lbp_2}所示。多尺度LBP使用$LBP_{P,R}$方法来表示领域参数，$P$ 表示邻域像素个数，$R$表示领域的圆周半径，图\ref{fig_lbp_2}分别依次给出了$LBP_{8,1}$、$LBP_{8,2}$和$LBP_{8,2.5}$三种模式。
\begin{figure}[!ht] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_lbp_2.eps}
  \bicaption{三种多尺度LBP~\label{fig_lbp_2}}{Three type of multi-scale LBP}
\end{figure}

（3）旋转不变LBP

邻域有$P$个点的LBP算子可以产生$2^P$种不同的模式，每个模式对应着$P$个相邻像素所组成的$2^P$个不同的二进制值。当图像发生旋转时，$P$个相邻像素也将绕着中心点沿圆形邻域的圆周旋转一定的角度，因此会使得$LBP_{P,R}$值发生改变。为了避免这个缺陷，Ojala又对$LBP_{P,R}$值进行重新定义，提出了具有旋转不变性的局部二值模式为：
\begin{equation}
LBP^{ri}_{P,R}=min\left \{ ROR(LBP_{P,R},i)|i=0,1,\cdots ,p-1 \right \}
\label{equ_lbp3}
\end{equation}
上式中，$LBP^{ri}_{P,R}$代表旋转不变 LBP 算子，$ROR(x,i)$为定义在$P$位数值$x$上的$i$位循环右移。如果对应图像采样的像素点来说，也就是对这$P$个像素点按照顺时针方向转动$i$次。由公式(\ref{equ_lbp3})看出，对于那些不断旋转得到的LBP模式取其最小值就是LBP的旋转不变模式。引入旋转不变模式定义后，使得LBP纹理特征对于图像旋转表现得更加鲁棒并且也减少了LBP模式的种类。

（4）LBP等价模式

尽管$LBP^{ri}_{P,R}$在理论上旋转不变性的性质，但在实际的应用中，并不具有很强的分类能力。这主要是因为具有旋转不变性的$LBP^{ri}_{P,R}$的不同模式的出现频率差异非常大造成的，其中有些特定的LBP模式出现频率达90\%以上，大大超过其它模式的出现频率。即模式中对应二进制串0和1的跳变次数为0或者只有两次跳变，这些特定的 LBP 模式被称为等价模式(Uniform LBP)。而对应的非等价模式，即为模式中对应二进制串0和1的跳变次数大于两次\supercite{Marcel2006On}。 如图\ref{fig_lbp_3}，给出了等价模式和非等价模式的例子。
\vspace{2em}
\begin{figure}[!ht] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_lbp_3.eps}
  \bicaption{等价模式与非等价模式示例~\label{fig_lbp_3}}{Examples of uniform and nonuniform patterns}
\end{figure}
\vspace{2em}

由图\ref{fig_lbp_3}可以看出，采用了等价模式后，二进制模式大大减少，模式的数量从最开始的$2^P$种减少到了$P(P-1)+2$种。实验表明，等价模式的LBP算子不受图像旋转和平移的影响，能够有效地表达纹理特征，又能起到降维的作用，并且对暗点、亮点、平滑区域、边缘等也具有较好的描述能力。

\subsection{HOG特征}
HOG(Histogram of Oriented Gradient)特征由Navneet Dalal和Bill Triggs于2005年提出\supercite{Dalal2005Histograms}，应用于行人检测问题。Hog特征表示局部目标的梯度直方图，在该特征被提出后，同样在物体检测(Object Detection)研究中得到了应用。由于HOG特征在目标检测领域取得了巨大的成功，它逐渐被扩展用于图像处理和模式识别的其他领域，比如：行为分析，场景分类，图像检索等等。Hog特征能够很好描述图像梯度或边缘的方向密度分布，因其在局部单元进行特征提取，对图像的旋转、平移以及光照变化都有一定的鲁棒性。在Hog特征被提出后，研究者们将其大量的应用在目标检测领域，并对其进行了很多改进，得到了不错的效果。目前学术界将HOG特征分为原始HOG和针对DPM模型对应的FHOG这两种，下面将分别介绍。

（1）原始HOG特征

对图片计算原始的HOG特征包括了梯度的计算，块（Block）和细胞（Cell）的分割，归一化特征权重和全局扫描图像这四个部分，下面将分别介绍这四个部分。

梯度计算。某像素点$(x,y)$点的梯度包括水平方向梯度$G_x$和垂直方向梯度$G_y$。其由公式(\ref{equ_hog_Gx}) 和公式(\ref{equ_hog_Gy}) 分别确定。最常用的方法是：首先用$[-1,0,1]$梯度算子对原图像做卷积运算，得到$x$方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用$[1,0,-1]^T$梯度算子对原图像做卷积运算，得到$y$方向（竖直方向，以向上为正方向）的梯度分量gradscaly。然后再用以下公式计算该像素点的梯度大小和方向。
\begin{equation}
G_x(x,y)=H(x+1,y)-H(x-1,y)
\label{equ_hog_Gx}
\end{equation}
\vspace{-4ex}
\begin{equation}
G_y(x,y)=H(x,y+1)-H(x,y-1)
\label{equ_hog_Gy}
\end{equation}

其中，$H(x,y)$表示在像素点$(x,y)$处的像素值。求导操作不仅能够捕获轮廓，人影和一些纹理信息，还能进一步弱化光照的影响。根据梯度值的计算，可以得到图像中像素点(x,y)的梯度大小和方向分别为：
\begin{equation}
G(x,y)=\sqrt{G_x(x,y)^2+G_y(x,y)^2}
\label{equ_hog_am}
\end{equation}
\vspace{-3ex}
\begin{equation}
\alpha (x,y)=tan^{-1}(\frac{G_y(x,y)}{G_x(x,y)})
\label{equ_hog_direc}
\end{equation}

Block和Cell。计算出来图像所有像素点的梯度之后，需要做进一步的梯度统计，用到的统计单元就是Block和Cell，它们之间的对应关系如图\ref{fig_hog}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.4\textwidth]{figure/fig_hog.eps}
  \bicaption{Block和Cell的关系~\label{fig_hog}}{Relationship between Block and Cell}
\end{figure}

可以看出，一个Block实际上是由若干个Cell组成的，每个Cell其实是统计出来的基于方向的梯度直方图。梯度直方图又可以分为无向直方图$B_1$（Contrast Insensitive）和有向直方图$B_2$（Contrast Sensitive）：
\begin{equation}
B_1(x,y)=round(\frac{p\theta(x,y)}{\pi})mod~p
\label{equ_hist}
\end{equation}
\vspace{-3ex}
\begin{equation}
B_2(x,y)=round(\frac{p\theta(x,y)}{2\pi})mod~p
\label{equ_hog_hist2}
\end{equation}
这里统一使用$B$来表示$B_1$和$B_2$。在图\ref{fig_hog}中，如果计算的是无向直方图(Contrast Insensitive)，则$0^{\circ}-360^{\circ}$被平均分成了8份($p=8$)，$0^{\circ}-22.5^{\circ}$和$180^{\circ}-202.5^{\circ}$可以被视为一个通道，以此类推，每个通道占用$45^{\circ}$。如果计算的是有向直方图(Contrast Sensitive)，则$0^{\circ}-360^{\circ}$被平均分了16份$(p=16)$，每个通道占用$22.5^{\circ}$。根据以上分类，可以得到位于$(x,y)$处的方向梯度特征向量为：
\begin{equation}
F(x,y)_b=\left\{\begin{matrix}
G(x,y), & if~b=B(x,y)\\
0,      & otherwise
\end{matrix}\right.
\label{equ_hog_vec}
\end{equation}
其中，$b$为直方图任意一个通道，即$b\in\left \{ 0,...,p-1 \right \}$。$p$为总通道数。Cell中每个像素点的梯度方向落入某个通道区域，则它对应的梯度大小被加入直方图的对应块。即对Cell中所有$(x,y)$的方向梯度特征向量$F(x,y)$求和。在实际应用中，一般采用9个通道的无向直方图统计$(p=9)$，并且每一个Block包含$2\times2=4$个Cell。

Block归一化及全局扫描。Block中4个Cell统计得到直方图存在尺度不一致的情况，所以需要根据每个Cell各自的权重进行归一化。一般通过$L1-norm$，$L2-norm$，$L1-sqrt$和$L2-Hys$等方式进行归一化操作。通过将整幅图像分割成小的连接区域称为Cell，每个Cell生成一个方向梯度直方图或者Cell中像素的边缘方向，一个Block内所有Cell的特征向量串联起来便得到该Block的HOG特征，即直方图的组合可表示出所检测目标的描述子，Block以一个Cell的大小为跨度在Cell-Map上全局扫描，得到的特征向量加入末尾，如图\ref{fig_hog_vec2}所示。为改善准确率，局部直方图可以通过计算图像中一个较大区域称为Block的光强作为度量，然后用这个度量归一化这个Block中的所有Cells。这个归一化过程完成了更好的照射、阴影不变性。与其他描述子相比，HOG得到的描述子保持了几何和光学转化不变性除非物体方向改变。
\begin{figure}[!ht] \centering
  \includegraphics[width=.5\textwidth]{figure/fig_hog_vec2.eps}
  \bicaption{通过全局扫描得到HOG特征向量~\label{fig_hog_vec2}}{HOG vector by Global Scan}
\end{figure}

由图\ref{fig_hog_vec2}可以看出，首先将一张图片分为若干个细胞单元（Cell），并按照梯度方向将其平均划分为9个区间（bin），然后在每个细胞单元里Cell里对所有像素的梯度方向在各个梯度方向区间进行直方图统计，得到一个9维的特征向量，每相邻的4个单元构成一个块（Block），把一个块内的特征向量联起来得到36维的特征向量，用块对样本图像进行扫描，扫描步长为一个单元，最后将所有块的特征串联起来，就得到了人体的特征。例如，对于$64\times128$的图像而言，每$8\times8$的像素组成一个Cell，每$2\times2$个Cell组成一个块，因为每个cell有9个特征，所以每个块内有$4\times9=36$个特征，以8个像素为步长，那么水平方向将有7个扫描窗口，垂直方向将有15个扫描窗口。也就是说，$64\times128$的图片，总共有$36\times7\times15=3780$个特征。

（2）FHOG特征\supercite{Felzenszwalb2008A,Felzenszwalb2010Object}

FHOG由美国芝加哥大学的Felzenszwalb等人\supercite{Felzenszwalb2008A}提出，是原始HOG特征的一个重要变形，它被验证在目标检测任务中某些类别的检测效果比原始HOG更好，并在目标检测，特别是行人、人脸检测当中得到广泛应用。FHOG和HOG最大的区别在于前者取消了Block的概念，对于一张输入大小为w$\times$h的图片，直接进行Cell的切分，得到一张基于Cell的图$C$，假设Cell的宽高都为$k$个像素，则$C(i,j)$满足：
\begin{equation}
0\leq i \leq \left\lfloor \frac{w-1}{k} \right\rfloor
\label{equ_fhog1}
\end{equation}
\vspace{-3ex}
\begin{equation}
0\leq j \leq \left\lfloor \frac{h-1}{k} \right\rfloor
\label{equ_fhog2}
\end{equation}
要将原始图像中的每个点$(x,y)$的方向梯度特征计算后相加到相应的$C(i,j)$中，具体的步骤和原始HOG梯度计算一致，其中$(i,j)$和$(x,y)$服从如下的关系：
\begin{equation}
i=\left\lfloor \frac{x}{k} \right\rfloor
\label{equ_fhog3}
\end{equation}
\vspace{-3ex}
\begin{equation}
j=\left\lfloor \frac{y}{k} \right\rfloor
\label{equ_fhog4}
\end{equation}
在FHOG中，每个$C(i,j)$对应四种不同的归一化因子，每个归一化因子记做$N_{\delta,\gamma}(i,j)$，且$\delta,\gamma\in\left \{ -1,1 \right \}$，则有：
\begin{equation}
N_{\delta,\gamma}(i,j)=\sqrt{||C(i,j)||^2+||C(i+\delta,j)||^2+||C(i,j+\gamma)||^2+||C(i+\delta,j+\gamma)||^2}
\label{equ_fhog5}
\end{equation}
每一个归一化因子的含义是$C(i,j)$所对应的Block的“梯度能量”，因为一个Cell对应四个Block，所以也对应四个“梯度能量”（归一化因子），每个因子都是对包含$(i,j)$在内的4个Cell组成的块Block的梯度能量的度量。在FHOG中，除了Cell图$C$之外，增加了另外一个Cell图，记作图$D$。图$C$和图$D$的区别在于图$C$统计无向的直方图(Contrast Insensitive)，图$D$统计有向的直方图（Contrast Sensitive）。经过4个不同方向的归一化因子归一化之后，图$C$可以计算得到$H_1(i,j)$，它是一个$4\times9$的特征矩阵，图D可以计算得到$H_2(i,j)$，它是一个$4\times18$的特征矩阵，这里将$H_1(i,j)$和$H_2(i,j)$进行组合得到$H(i,j)$:
\begin{equation}
H(i,j)=[H_1(i,j),H_2(i,j)]
\label{equ_fhog6}
\end{equation}
可见，H是$4\times27$维的矩阵，令:
\begin{equation}
V=\left\{ u_1,...,u_9 \right \} \cup \left \{ u_{10},...,u_{27} \right \}\cup \left \{ v_1,...,v_4 \right \}
\end{equation}
其中：
\begin{equation}
u_k(i,j)=\left\{\begin{matrix}
1, & if~j=k\\
0, & otherwise
\end{matrix}\right.
\label{equ_fhog7}
\end{equation}
\begin{equation}
v_k(i,j)=\left\{\begin{matrix}
1, & if~i=k\\
0, & otherwise
\end{matrix}\right.
\label{equ_fhog8}
\end{equation}
如上述定义，$u_k$和$v_k$也都是$4\times27$维的矩阵，FHOG则为$V$中所有的元素和$H$点乘求和的结果。$V$中有31个矩阵元素，所以得到的FHOG是一个31维的特征向量。它的前27维对应不同的方向通道（9个Contrast Insensitive 和18个Contrast Sensitive），剩余$4$个通道则是当前Cell在$4$个不同Block中的能量和。在PASCAL VOC数据库上实验表明，FHOG特征提取的算法在很多应用中的效果比原始HOG特征效果更好。

\subsection{非手工设计特征}

上述几种特征都是人类手工设计的特征。纵观计算机视觉领域的发展，其重要的一个方向便是手工设计特征的发展，这些特征是人类智慧的结晶。然而深度学习的发展，使得人脸检测及其它领域有了突破性的进展。然后在人脸检测问题上，传统方法和深度学习最本质的区别便在于对人脸特征的表达上。传统的机器学习技术在处理未加工过的数据时，体现出来的能力是有限的。而深度学习的能够通过多层非线性变换从大数据中自动学习不同抽象层次的特征，从而替代手工设计。深层的结构使深度学习具有极强的表达能力和学习能力，尤其擅长提取复杂的全局特征和上下文信息，而这是传统浅层模型难以做到的。然后他们的相似之处在于两张方法都统一在同一个框架下，只是在特征层面上的表达不同。

深度学习通过学习一种深层非线性网络结构，只需简单的网络结构即可实现复杂函数的逼近，并展现了强大的从大量无标注样本集中学习数据集本质特征的能力。深度学习能够获得可更好地表示数据的特征，同时由于模型的层次深（通常有5层、6层，甚至10多层的隐层节点，“深”的好处是可以控制隐层节点的数目为输入节点数目的多项式倍而非多达指数倍）、表达能力强，因此有能力表示大规模数据。对于图像、语音这种特征不明显（需要手工设计且很多没有直观的物理含义）的问题，深度模型能够在大规模训练数据上取得更好的效果。尤其是在语音识别方面，深度学习使得错误率下降了大约30\%，取得了显著的进步。特征工程的意义是找一个更好的空间去重构表达，把原始的数据对象映射到这个空间去表达，更便于多种应用。比如分类应用，最好是找到线性可分的空间，不止是神经网络可以代替人工找特征，理论上越是复杂的模型本身就是在代替人工找特征，只不过复杂模型的有效训练又成了难题。深层神经网络就是一种通用的复杂的模型，而深度学习很大程度上解决了它的训练问题。

深度学习正在取得重大进展，解决了人工智能界手工设计的特征所带来的局限性的问题。目前最新的人脸检测的论文都主要以深度学习方法为主，尽管深度学习方法存在着一些模型大、检测时间慢等缺点，但是我们相信，在未来的研究中，深度学习将会在各个领域取得更大的突破。
\section{基于类Haar特征的AdaBoost人脸检测}
\subsection{基于Adaboost学习算法}
人脸检测技术的突破发生在2001年，两位杰出的科研工作者Paul Viola和Michael Jones设计了出了一个快速而准确的人脸检测器：在获得相同甚至更好准确度的同时，速度提升了几十上百倍――在当时的硬件条件下达到了每秒处理15张图像的速度，已经接近实时速度25fps（即25帧每秒）。这不仅是人脸检测技术发展的一个里程碑，也标志着计算机视觉领域的研究成果开始具备投入实际应用的能力。为了纪念这一工作，人们将这个人脸检测器用两位科研工作者的名字命名，称之为Viola-Jones人脸检测器，或者简称为VJ人脸检测器。基于AdaBoost的学习算法有两个目的，一是从大量类Haar特征中选择出最优的一部分特征，二是将挑选出的特征用于训练有效的分类器。由于并不是每一个类Haar特征都能很好地表现人脸灰度分布特点，因此如何挑选出少量的最优的特征来组成有效的分类器成为我们要解决的主要问题。

每一个分类器对应一个矩形特征，通过将一个复杂的分类器拆分成简化的弱分类器，然后将弱分类器集成层叠组合形成有效的强分类器，从而将候选图像子窗口的人脸和非人脸区分开。具体的训练步骤如下所示：

\begin{itemize}
  \item 给定样本图像$(x_1,y_1),...,(x_n,y_n)$，其中$y_i = 0,1$分别代表负样本和正样本；
  \item 初始化权重：
    \begin{equation}
	w_{1,i} = \left\{
        \begin{array}{cc}
          \frac1{2m} & y_i = 0 \\
          \frac1{2l} & y_i = 1
        \end{array}
      \right.
    \end{equation}
        其中$m$表示负样本的数目，$l$表示正样本的数目；
  \item 对于$t = 1,...,T$：
    \begin{enumerate}
      \item 归一化权重：
        \begin{equation}
          w_{t,i} \leftarrow \frac{w_{t,i}}{\sum_{j=1}^n w_{t,j}}
        \end{equation}
            其中$w_t$是概率分布；
      \item 对于每个特征j训练分类器$h_j$，每个分类器有且只对应一种特征，分类器错误率是
        \begin{equation}
          \varepsilon_j = \sum_i w_i |h_j(x_i) - y_i|
        \end{equation}
      \item 选择错误率$\varepsilon_t$最小的分类器$h_t$；
      \item 更新权重：
        \begin{equation}
          w_{t+1,i} = w_{t,i}\beta_t^{1-e_i}
        \end{equation}
        其中，$\beta_t = \frac{\varepsilon_t}{1-\varepsilon_t}$如果样本$x_i$ 被正确分类$e_i = 0$，反之，$e_i = 1$；
    \end{enumerate}
  \item 最后得到强分类器为：
    \begin{equation}
      h(x) = \left\{
      \begin{array}{cc}
        1 & \sum_{t=1}^T \alpha_t h_t(x) \geq \frac{1}{2}\sum_{t=1}^T \alpha_t\\
        0 & 其他
      \end{array}\right.
    \end{equation}
        其中$\alpha_t = \lg\frac{1}{\beta_t}$
\end{itemize}

\subsection{级联分类器}
基于AbaBoost级联分类器如图\ref{fig_AdaBoostcascade}所示。层叠的分类器每一层都是由若干弱分类器组成的强分类器，首先采用较少的特征放在前级分类器，即弱分类器较少，以排除大部分非人脸区域，能够通过几乎全部的人脸，后级分类器采用更多的特征，即强分类器由更多的弱分类器组成，检测上一层通过的子窗口，加强检测人脸的区域。随着层数的增加，弱分类器的数量也在增加，同时从上一层过滤下来的子窗口数量在减少，从而能够保证较高的检测速度。这里的待测图像，一般将其按比例缩放进行归一化，每个图像的尺寸为$24\times24$像素的子窗口，依次判别是人脸还是非人脸。
\begin{figure}[!h] \centering
  \includegraphics[width=.7\textwidth]{figure/fig_AdaBoost_Cascade.eps}
  \bicaption[基于AdaBoost级联分类器结构]{基于AdaBoost级联分类器结构~\label{fig_AdaBoostcascade}}{Structure of AdaBoost-based cascade classifiers}
\end{figure}
\section{基于级联可变形部件模型的人脸检测}
\subsection{特征金字塔的构建}
在真实的场景下，人脸（目标物体）具有不同的大小和尺寸，着就要求检测器能够针对不同大小的人脸都可以检测，一般来讲，主要通过图像金字塔的方式进行检测，即在不改变检测器（滤波器）的情况下对不同分辨率的图像进行检测，以便得到完整的人脸检测，如图\ref{fig_hog_pyramid}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.4\textwidth]{figure/fig_hog_pyramid.eps}
  \bicaption[图像金字塔示例]{图像金字塔示例 ~\label{fig_hog_pyramid}}{Illustration of Image Pyramid }
\end{figure}

因此，在特征提取过程中，采用了特征金字塔的形式。首先，对待检测图片进行尺寸变换，一般通过降采样的方式，构造图像特征金字塔，然后对每一层的图像进行检测。通过对图像金字塔的分层检测，可以保证检测结果不会因为人脸的尺寸不同而产生错误，也可避免人脸大小不同导致的漏检。特征金字塔的结构就可以对各尺度下的特征结构进行编码，也就是说一幅图像的 HOG 特征是由多层的特征金字塔组成的。特征金字塔的使用保证了可变形部件模型对多角度目标的检测。上一章所述FHOG特征能够很好的勾勒出物体对象的轮廓，对微小形变和光照变化有很好的鲁棒性，不仅适合所涉及到的非生物目标的特征表示，也很适合来表示人脸。如下图\ref{fig_hog_face_1}所示：
\begin{figure}[!ht] \centering
  \includegraphics[width=.6\textwidth]{figure/fig_hog_face.eps}
  \bicaption{以FHOG 特征表示的人脸图像模型 ~\label{fig_hog_face_1}}{Face model represented by FHOG descriptor}
\end{figure}
\subsection{DPM人脸检测模型}
可变形部件模型（Deformable Part Model,~DPM）是由Felzenszwalb\supercite{Felzenszwalb2010Object}等人提出针对目标检测的模型，其基本的思想是基于滑动窗口中各部件以及各部件之间关系进行检测，最初用于人体检测。可变形部件模型（以下简称“DPM模型”）基于Dalal-Triggs检测器，采用了HOG多尺度特征金字塔，并引入了可变形部件，从而提高了模型对于物体类内多样性变化的适用性，即可以有效地处理姿态、形变等问题。DPM模型采用了金字塔的结构，所以可以有效地解决尺度问题，即检测目标不同大小的问题，这一思想在基于Haar Adaboost的人脸检测中已经有所体现。DPM模型除了包括一个粗粒度的模板，即根滤波器来覆盖整个对象，还包括多个高分辨率的部件（part）模板来对各部件进行匹配。在训练过程中，将框定待检测对象的图片作为正样本，将每一个对象的各部件的位置作为一个潜在变量。总结来看，DPM模型(Deformable Part Model)由三部分组成：
\begin{itemize}
\item  一个全局的根滤波器；
\item  几个高分辨率的部件模板(或叫做部件滤波器)；
\item  部件模板相对于根模板的空间位置，即形变值。
\end{itemize}

其基本的思想如下：

1、通过Hog特征模板来刻画每一部分，然后进行匹配。并且采用了金字塔，即在不同的分辨率上提取Hog特征。

2、利用提出的DPM模型，在进行目标检测时，检测窗口的得分等于部件的匹配得分减去模型变化的花费。

3、在训练模型时，需要训练得到每一个部件的Hog模板，以及衡量部件位置分布代价的参数。原文\supercite{Felzenszwalb2010Object}中提出了LatentSVM方法，将DPM的学习问题转换为一个分类问题：利用SVM学习，将部件的位置分布作为潜在变量(latent values)，模型的参数转化为SVM的分割超平面。具体实现中，作者采用了迭代计算的方法，不断地更新模型。

首先要计算一个HOG金字塔：通过计算标准图像金字塔中每层图像的特征得到特征金字塔，HOG金字塔中每一层的最小单位是细胞单元(cell)。滤波器(模板)就是一个权重向量，一个$w\times h$大小的滤波器$F$是一个含$w\times h\times9\times4$个权重的向量($9\times4$是一个HOG细胞单元的特征向量的维数)。所谓滤波器的得分就是此权重向量与HOG金字塔中$w \times h$大小子窗口的HOG特征向量的点积(DotProduct)。而检测窗口的得分是根滤波器的分数加上各个部件的分数的总和，每个部件的分数是此部件的各个空间位置得分的最大值，每个部件的空间位置得分是部件在该子窗口上滤波器的得分减去变形花费。

假设H是HOG金字塔，$p = (x, y, l)$ 表示金字塔第一层 $(x, y)$ 位置的一个细胞单元。$\varphi(H, p, w, h)$是将金字塔$H$中以$p$为左上角点的$w\times h$大小子窗口的HOG特征串接起来得到的向量。所以，滤波器$F$在此检测窗口上的得分为：$F_{\varphi(H, p, w, h)}$。此后，在不引起歧义的情况下，我们使用$\varphi(H,p)$代表$\varphi(H, p, w, h)$。所以，含$n$个部件的模型可以通过根滤波器$F_0$和一系列部件模型$(P_1,..., P_n)$来定义，其中$P_i = (F_i, v_i, s_i, a_i, b_i)$。$F_i$是第$i$个部件的滤波器；$v_i$和$s_i$都是二维向量，都以细胞单元为单位，$v_i$指明第$i$个部件位置的矩形中心点相对于根位置的坐标，$s_i$是此矩形的大小，$a_i$和$b_i$也都是二维向量，指明一个二次函数的参数，此二次函数用来对第$i$个部件的每个可能位置进行评分。

这里，使用$\beta$表示模型的参数，$F_0$表示根滤波器的参数，$F_1,...,F_7$为各部件的参数，$d_1,...,d_n$为各部件的形变值，$b$为偏移值，则模型的参数向量可以表示为：
\begin{equation}
\beta=(F_0,F_1,...F_n,d_1,...d_n,b)
\end{equation}
在进行检测时，使用了滑动窗口的方法，检测对象模型包括一个全局的根滤波器和很多部件模型。每一个部件模型都制定了一个具体的空间模型和部件滤波器。空间模型定义了对于一个部件相对于检测窗口允许变化的范围空间以及在该位置的变形代价。待检测窗口的得分是根滤波器的得分加上各部分最大重合部分的得分减去变形代价。若检测窗口的得分高于阈值，则说明检测窗口中包含待检测物体，否则不包含。令$\varphi(x,y)$为检测窗口对应的图像特征，$x$表示检测窗口的位置，$z$表示各部件的位置，那么该图像的最终得分如下:
\begin{equation}
score(x)=\max \limits_{z\in Z(x)}\beta\cdot \varphi(x,z)
\label{equ_dpm_score}
\end{equation}
在公式(\ref{equ_dpm_score})中，$\beta$是由训练得到。通过滑动窗口的方式，最终待检测窗口
的得分为根滤波器的分值减去各个部件的偏移代价。其偏移的代价本质上代表着部件模型和主模型的空间先验知识。其中主模型主要是以根滤波器计算得到，而根滤波器则便是利用原始Hog特征训练得到的正面模型。虽然DPM模型的计算复杂度要比基于Haar Adaboost或LBP Adaboost方法要高，但是可以通过动态规划和广义距离变换等方式来计算部件的最优位置，并可通过指令集优化的方式进行计算。一般花费$O(nk)$的时间就可计算一个滤波器的响应值，其中$n$是模型中部件的个数，而$k$是特征金字塔中位置的总数文献\parencite{Felzenszwalb2004Distance}和文献\parencite{Felzenszwalb2005Pictorial}中有详细的解释。
%其中，参数$\beta$由训练得出。待检测窗口的得分是根滤波器的得分加上各部分最大重合部分的得分减去变形代价，这与传统的基于部件的模型相似。根滤波器和部件滤波器都是由计算HOG特征与权值之间的点积得到。根滤波器等同于Dalal-Triggs模型，计算各部件的特征的分辨率是根滤波器的两倍。
%
%本文提到的模型是固定规模的，通过在图像金字塔上检测对象，从而达到对不同分辨率进行检测的效果。高得分的根位置定义了一次检测，产生高得分根位置的部件位置定义了一个完整的目标假设。通过定义每个根位置的综合得分(overall score)，可以检测目标的多个实例(假设每个根位置上最多一个实例)。这种方法与滑动窗口检测器有关联，因为可以认为$score(p_0)$ 是检测窗口在指定根位置的得分。通过使用动态规划和广义距离变换(min-convolution)来计算部件的最优位置(是根位置的函数)，此方法非常高效，花费$O(nk)$时间计算一个滤波器的响应值，$n$是模型中部件的个数，$k$是特征金字塔中位置的总数，
\subsection{Structured SVM模型训练}
（1）隐藏变量SVM――Latent SVM

在模型的训练过程中，引入了专门为弱监督设计的隐支持向量机(Latent Support Vector Machine,~LSVM)。考虑一个分类器，在 LSVM 中每个样本$x$的得分可以使用下面的形式表示：
\begin{equation}
f_{\beta}(x)=\max \limits_{z\in Z(x)}\beta\cdot \varphi(x,z)
\label{equ_lsvm_score}
\end{equation}
这里$\beta$是模型参数向量，$z$是隐藏变量。集合$Z(x)$定义了样本$x$所有可能的隐藏变量值。通过对此得分值进行阈值化，可以获得样本$x$的二分类类标。类比经典SVM算法，我们使用带类标的样本集$D = (<x1, y1>, ..., <xn,yn>), yi\in{-1, 1}$来训练参数$\beta$，优化目标函数为：
\begin{equation}
L_D(\beta)=\frac{a}{b}||\beta||^2+C\sum_{i=1}^{n}\max(0,1-y_if_{\beta}(x_i))
\label{equ_lsvm_optims}
\end{equation}
其中$\max(0,1-y_if_{\beta}(x_i))$是标准铰链损失函数（hinge loss），常数$C$控制正则项的相对权重。如果每个样本的隐藏变量有唯一可能值$|Z(x_i)|=1$，则$f_{\beta}$是$\beta$的线性函数，此时变为线性SVM问题，这是LSVM的一个特例。

（2）半凸规划

LSVM最终是一个非凸规划(non-convex)问题。然而，下面所讨论的情况下LSVM是半凸规划(semi-convexity)问题，一旦将隐藏信息指定给正样本则训练问题变为凸规划问题。几个凸函数的最大值问题是凸规划问题。在线性SVM中，有:
\begin{equation}
f_{\beta}(x)=\beta\cdot \varphi(x)
\label{equ_lsvm_convex}
\end{equation}

$f$是$\beta$的线性函数，此时铰链损失函数对每个样本都是凸的，因为它是两个凸函数的最大值。注意到公式(\ref{equ_lsvm_score})中定义的$f_{\beta}$是一系列函数的最大值，而这些函数都是$\beta$的线性函数，因此$f_{\beta}$是$\beta$的凸函数。所以当$y_i = -1$时，两个函数$f(x)=0$和$f(x)=1-y_if_{\beta}(x_i)$都是$\beta$的凸函数，所以铰链损失函数$\max(0,1-y_if_{\beta}(x_i))$是$\beta$的凸函数。也就是说，只有当样本为负样本时，损失函数是$\beta$的凸函数。我们将损失函数的这一性质叫做半凸(semi-convexity)。对于正样本$(yi= 1)$来说，LSVM的铰链损失函数不是凸函数，因为它是一个凸函数$f(x)= 0$和一个凹函数$f(x)=1-y_if_{\beta}(x_i)$的最大值。但是，当LSVM的正样本的隐藏变量具有唯一可能的取值时，$f_{\beta}(x_i)$是$\beta$的线性函数，因此损失函数是$\beta$的凸函数，再加上半凸性质，公式(\ref{equ_lsvm_optims})变为凸规划问题。

（3）模型训练步骤

模型的训练过程主要包括以下几个步骤：

1）根滤波器初始化。首先根据训练图片的标记确定根滤波器的规模，并初始化根滤波器，然后使用支持向量机(SVM)来训练根滤波器$F_0$。

2）根滤波器的更新。在确定了根滤波器之后，则对训练集中的每一个样本寻找响应最大且满足与标记位置区域大于指定覆盖率的位置，并以此位置为准来更新训练图像的标记位置，然后使用新位置标记的样本以及随机选取的负样本来更新根滤波器$F_0$。

3）部件滤波器初始化。在上一步骤的基础上，通过贪心的策略选择得分最大的区域，并将其作为部件滤波器的位置。

4）滤波器更新。滤波器的更新主要通过正负样本的不断更新得到。其中正样本一般选择覆盖率大于50\%的样本，而负样本选择在旧滤波器的检测中得分很高的负样本。通过上述选择的样本集进行迭代式的训练，最终在满足一定收敛的情况下即可得到DPM模型。
%\subsection{算法复杂度分析}
\section{本章小结}
本章主要介绍了人脸检测的研究概述和本文所采用的人脸检测的方法，另外介绍了在人脸检测和识别当中用到的主流的特征。人脸检测是非常重要的预处理部分，其不仅考虑到多视角下的检测率和误检率，而且要保证检测的实时性。基于Haar特征的Adaboost人脸检测器因其特征简单，所以速度很快，但是检测率低，误检率却很高，且在处理多视角人脸中显得不足，而基于DPM模型的人脸检测因其本身模型的适应性以及FHOG特征金字塔模型的有效性，使得多姿态人脸检测能够保证很高的检测率和很低的误检率，但是速度较Haar-Adaboost模型较慢，这部分可通过工程上的实现，比如并行加速、指令集优化来弥补。详情在实验结果与分析部分会给出介绍。